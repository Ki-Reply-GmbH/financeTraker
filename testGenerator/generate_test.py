from setup import chain, chain_for_healer
import ast
import os
from functionGraber import get_functions_and_imports, format_function_as_string, get_test_functions
from test_analyzer import run_tests
from self_healer import Healer
import json
from testGenConfig import source_dir, test_dir, project_root_module_name, root_dir
from self_heal_data_structure import TestFunctionGenerator,GeneratedTestForFunction
from data_store import test_function_generators
from pydantic import BaseModel
from self_heal_data_structure import statusEnum
import re  
from typing import Tuple
get_source_file = os.path.join(source_dir, 'services', 'user_services.py')  



def start_healing(test_function, test_file_path, function_code, test_run_output):
    # Create a Healer instance
    healer = Healer(test_function, test_file_path, function_code, test_run_output)
    # Start the healing process
    healer.heal()



def generate_test_with_LLM():
    test_function_generator = TestFunctionGenerator()
    test_generated = GeneratedTestForFunction()
    current_function=''
    
    functionsWithImport  = get_functions_and_imports(get_source_file, project_root_module_name, root_dir)
    

    
    for function in functionsWithImport:
        
        #Save the function inside data structure for further tracking
        test_function_generator.function_name = function['name']
        test_function_generator.function_code = function['code']
        current_function=test_function_generator.function_name
        
        #print(f"current function name:\n {current_function}")
        # Format the function as a string
        formatted_string = format_function_as_string(function)    
        #print(f"Formatted function string:/n {formatted_string}")
        
        # Invoke the LLM chain and get the response
        response = chain.invoke({"input": formatted_string},return_only_outputs=True)
        #print(response)
        response = json.dumps(response)
        
        # print(response)
        
        # Handle multiple parts of the response: "common code", "test1", "test2", etc.
        
        response_code,response_code_dict = extract_code_from_llm_response(response, test_function_generator)
        #print(f"Response code extracted:\n{response_code}")
        #print(type(response_code))
        
        test_code_response = extract_only_test_code_from_llm_response(response)
        
        # Iterate over the test cases in the response and store them in the pydantic class
        for test_key, test_code in test_code_response.items():
            function_name = re.findall(r'def (\w+)\(', test_code)
            function_name_str = function_name[0]
            generated_test = GeneratedTestForFunction(
                test_function_key=test_key,  # Store the test key (e.g., 'test1')
                test_function_code=test_code,
                test_function_generated_name= function_name_str,# Store the test code generated by LLM
                status=statusEnum.NOT_STARTED  # Assume status is DONE unless errors occur later
            )
            # Append the generated test to the list for this function
            test_function_generator.generated_tests.append(generated_test)
        
        #response_code_json_to_dict = json.loads(response_code)
        # save_response_code(response_code_dict)
        
        #print(f"Response code is in dict: {response_code_dict}")
        
        #print(response_code)
      
        test_file_path = save_test_to_file(function.get('name'), response_code) #make sure to handle noNameFound
        print(f"Test file saved at: {test_file_path}")
        
        # Get the test functions from the saved file
        #test_functions = get_test_functions(test_file_path)

        for generated_test in test_function_generator.generated_tests:
            test_function_code_name = generated_test.test_function_generated_name
            # Run tests on the function
            failure_summary = run_tests(test_file_path, test_function_code_name)
            
            if failure_summary:
                
                #save_failure_summary(failure_summary)
                
                # Update the corresponding test with error information
                generated_test.test_error = failure_summary
                generated_test.status = statusEnum.FAILED  # Update status or retry if needed
                
                print("Healing process started")
                # Start the healing process if tests fail
                response_failure = handle_failure_and_invoke_chain(
                    test_function_generator.function_name,
                    test_function_generator.function_code,
                    test_function_generator.function_common_code,  # Assuming this is part of test_function_generator
                    test_function_code_name,
                    generated_test.test_function_code,
                    generated_test.test_error
                )
                
                print(f"Response for failure and heal :\n {response_failure}")
                extract_code_from_llm_response_for_failure(response_failure)
                
                start_healing(test_function_code_name, test_file_path, function.get('code', 'noCodeFound'), failure_summary)
                
            else:
                generated_test.status = statusEnum.DONE
                
            # Break after the first test function for now (as per your original code)
            break
        break
    # print("------")
    # print(f"Function Name:{test_function_generator.function_name}")
    # print(f"Function Code:\n{test_function_generator.function_code}")
    # print(f"Function common Code:\n{test_function_generator.function_common_code}")
    # print("Generated Tests:")
    
    # for test in test_function_generator.generated_tests:
    #     print(f"  Test Function Key:{test.test_function_key}")
    #     print(f"  Test Function Code:\n{test.test_function_code}")
    #     print(f"  Test Function Generated Name:{test.test_function_generated_name}")
    #     print(f"  Test Error:{test.test_error}")
    #     print(f"  Retry Count:{test.retry_count}")
    #     print(f"  Status:{test.status}")
    #     print("------")


def handle_failure_and_invoke_chain(function_name, function_code, common_code, test_function_code_name, test_function_code, test_error):
    # Create the input for the chain based on the provided parameters
    input_data = json.dumps({
        "function_name": function_name,
        "function_code": function_code,
        "function_common_code": common_code,
        "generated_test_function_name": test_function_code_name,
        "test_function_code": test_function_code,
        "test_error": test_error
    }, separators=(',', ':'))
    #input_to_json = json.dumps(input_data)
    
    # Log the input data for debugging
    print(f"Invoking chain with the following input data:\n{json.dumps(input_data, indent=4)}")
    
    # Invoke the chain with the input data and return only the outputs
    response = chain_for_healer.invoke({"input": input_data}, return_only_outputs=True)
    
    # Handle the response as needed
    #print(f"Chain response: {response}")
    return response



def extract_code_from_llm_response_for_failure(response_upon_failure):
    # Extracting the values
    corrected_common_code = response_upon_failure['text']['corrected_common_code']
    corrected_test_code = response_upon_failure['text']['corrected_test_code']

    # Printing them
    print("Corrected Common Code:", corrected_common_code)
    print("Corrected Test Code:", corrected_test_code)


    
    
def extract_code_from_llm_response(response: str, test_function_generator: TestFunctionGenerator) -> Tuple[str, dict]:
    """
    Extracts and concatenates the different sections of the LLM response, including 'commoncode', 'test1', 'test2', etc.
    Uses a for loop to count and process the test cases. Handles missing or None values gracefully.
    
    """
    # Initialize an empty string for the full code
    full_code = ""
    full_code_dict = {}

    try:
        # Parse the response into a Python dictionary
        response_dict = json.loads(response)
        
        # Extract the common code (imports and shared fixtures)
        common_code = response_dict.get('text', {}).get('commoncode')
        if common_code:
            common_code = common_code.strip()  # Remove surrounding spaces
            print(f"Common code extracted:\n{common_code}")
            full_code_dict['commoncode'] = common_code
            full_code += common_code + "\n\n"  # Add common code with spacing
            
            test_function_generator.function_common_code = common_code
            
        else:
            print("No common code found in response")
        
        # Initialize a list to gather all 'test' keys
        test_keys = [key for key in response_dict['text'] if key.startswith("test") and response_dict['text'][key] is not None]

        # Sort the test keys by the numeric value of their name (test1, test2, ...)
        sorted_test_keys = sorted(test_keys, key=lambda x: int(x.replace("test", "")))

        # Iterate over the test keys using a for loop
        for test_key in sorted_test_keys:  # Sorted ensures processing in correct order
            test_code = response_dict['text'][test_key].strip()  # Extract and strip each test case
            print(f"{test_key} extracted:\n{test_code}")
            full_code_dict[test_key] = test_code  # Add the test code to the dictionary
            # Ensure the test code is properly indented and formatted
            full_code += test_code + "\n\n"
        
        print(f"Final concatenated code:\n{full_code}")
        return full_code.strip(),full_code_dict  # Return final concatenated code without extra trailing spaces
    
    except json.JSONDecodeError:
        print("Invalid JSON format in response.")
        return ""
    except KeyError as e:
        print(f"Missing key in the response: {e}")
        return ""
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return ""


def extract_only_test_code_from_llm_response(response):
    """
    Extracts only the test sections ('test1', 'test2', etc.) from the LLM response.
    Skips 'commoncode' and returns only the test cases in a dictionary.
    """
    # Initialize an empty dictionary to store test codes
    test_code_dict = {}

    try:
        # Parse the response into a Python dictionary
        response_dict = json.loads(response)
        
        # We are not storing 'commoncode', just printing it for logging/debugging purposes
        common_code = response_dict.get('text', {}).get('commoncode')
        if common_code:
            common_code = common_code.strip()  # Remove surrounding spaces
            #print(f"Common code extracted (not stored):\n{common_code}")
        
        # Collect all test-related keys like 'test1', 'test2', etc.
        test_keys = [key for key in response_dict['text'] if key.startswith("test") and response_dict['text'][key] is not None]

        # Sort the test keys by numeric value (test1, test2, ...)
        sorted_test_keys = sorted(test_keys, key=lambda x: int(x.replace("test", "")))

        # Add only test codes to the dictionary
        for test_key in sorted_test_keys:
            test_code = response_dict['text'][test_key].strip() 
            #print("inside the test extarctor")# Clean and extract test code
            #print(f"{test_key} extracted:\n{test_code}")
            test_code_dict[test_key] = test_code  # Store only the test code
        
        # Return the dictionary of test codes
        return test_code_dict
    
    except json.JSONDecodeError:
        print("Invalid JSON format in response.")
        return {}
    except KeyError as e:
        print(f"Missing key in the response: {e}")
        return {}
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return {}



def save_test_to_file(function_name, test_code):
   
    # Construct the test file name and path
    test_file_name = f"test_{function_name}.py"
    test_file_path = os.path.join("tests", test_file_name)  # Save in 'tests' folder
    
    # Print the path where the file will be saved
    print(f"Saving test code to: {test_file_path}")
    
    # Ensure the directory exists
    try:
        os.makedirs(os.path.dirname(test_file_path), exist_ok=True)
        print(f"Directory created or already exists: {os.path.dirname(test_file_path)}")
    except Exception as e:
        print(f"Error creating directory: {e}")
        return ""
    
    # Check if test_code is empty before writing
    if not test_code.strip():
        print("Test code is empty. File will not be written.")
        return ""

    # Write the test code to the file
    try:
        with open(test_file_path, 'w') as test_file:
            test_file.write(test_code)
        print(f"Test code written successfully to: {test_file_path}")
    except Exception as e:
        print(f"Error writing to file: {e}")
        return ""

    return test_file_path


if __name__ == "__main__":
    # capture_working_function_responses()
    generate_test_with_LLM()
   # save_response_code()



























# import json

# def get_function_in_JSON_Object_List(functions):
#     json_obj = {}

#     for function in functions:
#         function_code = ast.unparse(function)
#         escaped_code = json.dumps(function_code)
#         json_obj[function.name] = escaped_code

#     return list(json_obj.items())


# # def generate_test_with_LLM(func_list):
# #     pass
# # func_list = get_function_in_JSON_Object_List(functions)
# # print(func_list[0])
# # # for func_name, escaped_code in func_list:
    
# # func_name, escaped_code = func_list[0]
# # # response= llm.invoke({"input": "give me the code for palindrome number"})

# # # print(response)

# # response={'input': 'give me the code for palindrome number', 'text': {"code":"def add_numbers(a, b):\n\tsum = a + b\n\tprint(sum)\n\tif sum > 10:\n\t\treturn True\n\telse:\n\t\treturn False\n"}}

# # # Extract the 'code' value
# # code = response['text']['code']
# # # print(code)
# def llm_invocation(input):
#     response= llm.invoke({"input": input})
#     code = response['text']['code']
#     return code
